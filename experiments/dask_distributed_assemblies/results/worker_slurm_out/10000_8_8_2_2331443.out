2024-08-09 08:18:02,232 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:42423'
2024-08-09 08:18:02,232 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:39367'
2024-08-09 08:18:02,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:33100'
2024-08-09 08:18:02,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:39679'
2024-08-09 08:18:02,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:41909'
2024-08-09 08:18:02,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:34875'
2024-08-09 08:18:02,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:40304'
2024-08-09 08:18:02,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.9:40631'
2024-08-09 08:18:02,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-5x95__8b', purging
2024-08-09 08:18:02,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-pyrpz3et', purging
2024-08-09 08:18:02,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-8f1ojh7z', purging
2024-08-09 08:18:02,842 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-opzythb9', purging
2024-08-09 08:18:02,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-2kmusxx_', purging
2024-08-09 08:18:02,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-j750nlmt', purging
2024-08-09 08:18:02,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-iraa__21', purging
2024-08-09 08:18:02,843 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-b7a56oh_', purging
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:40778
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:41531
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:40778
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:43359
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:41531
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-1
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-3
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:43359
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:45883
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:45336
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:44531
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:44395
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-5
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:43026
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:43913
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.9:35974
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:45336
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:45883
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:38056
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:43026
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:43913
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-0
2024-08-09 08:18:03,378 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.9:35974
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-2
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-7
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-6
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:42711
2024-08-09 08:18:03,378 - distributed.worker - INFO -           Worker name:           SLURMCluster-2-4
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:40431
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:35195
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:33213
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -          dashboard at:           10.34.59.9:34203
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-okqm_zxl
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7yxwo9d0
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ucsrl5jf
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -               Threads:                          1
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_5r_9nmo
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9k27dmds
2024-08-09 08:18:03,378 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xwtuf0nd
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wpzur82v
2024-08-09 08:18:03,378 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5hd4xhj5
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,803 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,804 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,804 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,804 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,804 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,804 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,804 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,805 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,805 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,806 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,806 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,806 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,806 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,807 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,807 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,808 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,812 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,813 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,813 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,813 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,813 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,814 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,814 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,815 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,815 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,816 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,816 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,816 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
2024-08-09 08:18:03,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 08:18:03,817 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44141
2024-08-09 08:18:03,817 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 08:18:03,817 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44141
slurmstepd: error: *** JOB 2331443 ON cl-node009 CANCELLED AT 2024-08-09T08:18:13 ***
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:43913. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:35974. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:45883. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:43359. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:41531. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:40778. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:45336. Reason: scheduler-close
2024-08-09 08:18:13,186 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.9:43026. Reason: scheduler-close
2024-08-09 08:18:13,189 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:40304'. Reason: scheduler-close
2024-08-09 08:18:13,190 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:41909'. Reason: scheduler-close
2024-08-09 08:18:13,192 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,192 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,192 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:33100'. Reason: scheduler-close
2024-08-09 08:18:13,193 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:34875'. Reason: scheduler-close
2024-08-09 08:18:13,191 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.9:48972 remote=tcp://10.34.59.1:44141>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.9:48972 remote=tcp://10.34.59.1:44141>: Stream is closed
2024-08-09 08:18:13,193 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:39367'. Reason: scheduler-close
2024-08-09 08:18:13,193 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:42423'. Reason: scheduler-close
2024-08-09 08:18:13,194 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:39679'. Reason: scheduler-close
2024-08-09 08:18:13,194 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.9:40631'. Reason: scheduler-close
2024-08-09 08:18:13,194 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,195 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,195 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,195 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,195 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,195 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,197 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,197 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,197 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,197 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,197 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,198 - distributed.nanny - INFO - Worker closed
2024-08-09 08:18:13,198 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44141; closing.
2024-08-09 08:18:13,198 - distributed.nanny - INFO - Worker closed
