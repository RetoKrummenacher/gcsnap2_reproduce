2024-08-09 05:53:47,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43045'
2024-08-09 05:53:47,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42047'
2024-08-09 05:53:47,606 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42070'
2024-08-09 05:53:47,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:38861'
2024-08-09 05:53:47,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36530'
2024-08-09 05:53:47,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33420'
2024-08-09 05:53:47,612 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46703'
2024-08-09 05:53:47,613 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35365'
2024-08-09 05:53:48,694 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46164
2024-08-09 05:53:48,694 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43977
2024-08-09 05:53:48,694 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46164
2024-08-09 05:53:48,694 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43977
2024-08-09 05:53:48,694 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 05:53:48,694 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 05:53:48,694 - distributed.worker - INFO -          dashboard at:           10.34.59.2:33618
2024-08-09 05:53:48,694 - distributed.worker - INFO -          dashboard at:           10.34.59.2:40006
2024-08-09 05:53:48,694 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,694 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,694 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,694 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,694 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,694 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,695 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qhion5yn
2024-08-09 05:53:48,695 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vy5ixj5_
2024-08-09 05:53:48,695 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,695 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,696 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46694
2024-08-09 05:53:48,696 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46694
2024-08-09 05:53:48,697 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 05:53:48,697 - distributed.worker - INFO -          dashboard at:           10.34.59.2:33251
2024-08-09 05:53:48,697 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,697 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37267
2024-08-09 05:53:48,697 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:32907
2024-08-09 05:53:48,697 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,697 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37267
2024-08-09 05:53:48,697 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:32907
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1_p4qzu2
2024-08-09 05:53:48,697 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 05:53:48,697 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 05:53:48,697 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO -          dashboard at:           10.34.59.2:35859
2024-08-09 05:53:48,697 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41150
2024-08-09 05:53:48,697 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43328
2024-08-09 05:53:48,697 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,697 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,697 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43328
2024-08-09 05:53:48,697 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,697 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,697 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 05:53:48,697 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-s9m22vj4
2024-08-09 05:53:48,697 - distributed.worker - INFO -          dashboard at:           10.34.59.2:39908
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z_061nxs
2024-08-09 05:53:48,697 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,698 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,698 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,697 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:40822
2024-08-09 05:53:48,698 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,698 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,698 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:40822
2024-08-09 05:53:48,698 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0jtc8fet
2024-08-09 05:53:48,698 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 05:53:48,698 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,698 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41783
2024-08-09 05:53:48,698 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,698 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,698 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,698 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,698 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3uizi_n3
2024-08-09 05:53:48,698 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,703 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:44912
2024-08-09 05:53:48,703 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:44912
2024-08-09 05:53:48,703 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 05:53:48,703 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43057
2024-08-09 05:53:48,703 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41488
2024-08-09 05:53:48,703 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:48,703 - distributed.worker - INFO -               Threads:                          1
2024-08-09 05:53:48,703 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 05:53:48,703 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wrs_59uq
2024-08-09 05:53:48,703 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,062 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,062 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,063 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,063 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,063 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,063 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,066 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,066 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,067 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,067 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,067 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,067 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,067 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,067 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,067 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,068 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,075 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,075 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,075 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,085 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,085 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,086 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:49,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 05:53:49,087 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41488
2024-08-09 05:53:49,087 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 05:53:49,088 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41488
2024-08-09 05:53:52,464 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 05:53:52,480 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 05:53:52,652 - distributed.worker.memory - WARNING - Worker is at 9% memory usage. Resuming worker. Process memory: 173.72 MiB -- Worker memory limit: 1.86 GiB
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:40822. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46694. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37267. Reason: scheduler-close
slurmstepd: error: *** JOB 2330374 ON cl-node002 CANCELLED AT 2024-08-09T05:54:08 ***
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:44912. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:32907. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43977. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43328. Reason: scheduler-close
2024-08-09 05:54:08,058 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46164. Reason: scheduler-close
2024-08-09 05:54:08,059 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57834 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57834 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,059 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57828 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57828 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,059 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57836 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57836 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,059 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57826 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57826 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,060 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57830 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57830 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,061 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57823 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57823 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,061 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57832 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57832 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,061 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57822 remote=tcp://10.34.59.1:41488>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:57822 remote=tcp://10.34.59.1:41488>: Stream is closed
2024-08-09 05:54:08,064 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:38861'. Reason: scheduler-close
2024-08-09 05:54:08,067 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:42070'. Reason: scheduler-close
2024-08-09 05:54:08,067 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46703'. Reason: scheduler-close
2024-08-09 05:54:08,068 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35365'. Reason: scheduler-close
2024-08-09 05:54:08,068 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33420'. Reason: scheduler-close
2024-08-09 05:54:08,070 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43045'. Reason: scheduler-close
2024-08-09 05:54:08,070 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,070 - distributed.nanny - INFO - Worker closed
2024-08-09 05:54:08,070 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36530'. Reason: scheduler-close
2024-08-09 05:54:08,070 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,071 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:42047'. Reason: scheduler-close
2024-08-09 05:54:08,071 - distributed.nanny - INFO - Worker closed
2024-08-09 05:54:08,069 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 445, in wait_for
    return fut.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 559, in connect
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 140, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x2b2b12052770>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 605, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-08-09 05:54:08,072 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 432, in wait_for
    await waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-08-09 05:54:08,073 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,073 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,073 - distributed.nanny - INFO - Worker closed
2024-08-09 05:54:08,073 - distributed.nanny - INFO - Worker closed
2024-08-09 05:54:08,073 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 445, in wait_for
    return fut.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 559, in connect
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 140, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x2b6d27a9f3d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 605, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-08-09 05:54:08,075 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,076 - distributed.nanny - INFO - Worker closed
2024-08-09 05:54:08,079 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41488; closing.
2024-08-09 05:54:08,079 - distributed.nanny - INFO - Worker closed
