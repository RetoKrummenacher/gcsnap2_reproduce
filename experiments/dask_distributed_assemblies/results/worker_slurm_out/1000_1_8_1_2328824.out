2024-08-09 03:59:06,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43957'
2024-08-09 03:59:06,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41554'
2024-08-09 03:59:06,571 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33371'
2024-08-09 03:59:06,571 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45912'
2024-08-09 03:59:06,571 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:39863'
2024-08-09 03:59:06,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44730'
2024-08-09 03:59:06,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:39594'
2024-08-09 03:59:06,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35729'
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41684
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33476
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33109
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:45299
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41684
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33476
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37428
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33109
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:45299
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:40004
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37428
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42165
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41352
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34845
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:40004
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:45731
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46328
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36449
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42445
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46328
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38205
2024-08-09 03:59:07,798 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36449
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ttvpiib6
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42989
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-33jcvgfj
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_47u30i3
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37758
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6j3uiqk6
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46415
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-a1str9kl
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ak044cn0
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -               Threads:                          1
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3h0ktzm2
2024-08-09 03:59:07,798 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hbg6i353
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:07,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,216 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,217 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,217 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,217 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,218 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,218 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,218 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,218 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,219 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,219 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,219 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,220 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,219 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,220 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,220 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,220 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,220 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,220 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,221 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,221 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,221 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,221 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,221 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,222 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,222 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,222 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
2024-08-09 03:59:08,224 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 03:59:08,224 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46415
2024-08-09 03:59:08,225 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 03:59:08,225 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46415
slurmstepd: error: *** JOB 2328824 ON cl-node002 CANCELLED AT 2024-08-09T03:59:17 ***
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:45299. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46328. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33476. Reason: scheduler-close
2024-08-09 03:59:17,064 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37428. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33109. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36449. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:40004. Reason: scheduler-close
2024-08-09 03:59:17,065 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41684. Reason: scheduler-close
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60702 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60702 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60698 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60698 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60699 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60699 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60708 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60708 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60710 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60710 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60704 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60704 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,066 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60696 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60696 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,067 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60706 remote=tcp://10.34.59.1:46415>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:60706 remote=tcp://10.34.59.1:46415>: Stream is closed
2024-08-09 03:59:17,069 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35729'. Reason: scheduler-close
2024-08-09 03:59:17,070 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:39594'. Reason: scheduler-close
2024-08-09 03:59:17,070 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41554'. Reason: scheduler-close
2024-08-09 03:59:17,070 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43957'. Reason: scheduler-close
2024-08-09 03:59:17,071 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45912'. Reason: scheduler-close
2024-08-09 03:59:17,071 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,072 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,072 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,072 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33371'. Reason: scheduler-close
2024-08-09 03:59:17,072 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,072 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44730'. Reason: scheduler-close
2024-08-09 03:59:17,072 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:39863'. Reason: scheduler-close
2024-08-09 03:59:17,073 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,073 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,073 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,073 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,073 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,073 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,075 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,075 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,075 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,075 - distributed.nanny - INFO - Worker closed
2024-08-09 03:59:17,076 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46415; closing.
2024-08-09 03:59:17,076 - distributed.nanny - INFO - Worker closed
