2024-08-09 07:50:32,029 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44943'
2024-08-09 07:50:32,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33472'
2024-08-09 07:50:32,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36382'
2024-08-09 07:50:32,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:37401'
2024-08-09 07:50:32,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46359'
2024-08-09 07:50:32,043 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35521'
2024-08-09 07:50:32,043 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35504'
2024-08-09 07:50:32,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44453'
2024-08-09 07:50:32,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43890'
2024-08-09 07:50:32,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:37565'
2024-08-09 07:50:32,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42724'
2024-08-09 07:50:32,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45838'
2024-08-09 07:50:32,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36235'
2024-08-09 07:50:32,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42362'
2024-08-09 07:50:32,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35042'
2024-08-09 07:50:32,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:34267'
2024-08-09 07:50:33,147 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37804
2024-08-09 07:50:33,147 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37804
2024-08-09 07:50:33,147 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-2
2024-08-09 07:50:33,147 - distributed.worker - INFO -          dashboard at:           10.34.59.2:39484
2024-08-09 07:50:33,147 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,147 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,147 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,147 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,147 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xb_6g8as
2024-08-09 07:50:33,147 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,149 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38452
2024-08-09 07:50:33,149 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38452
2024-08-09 07:50:33,149 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-0
2024-08-09 07:50:33,149 - distributed.worker - INFO -          dashboard at:           10.34.59.2:32832
2024-08-09 07:50:33,149 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,149 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,149 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,149 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,149 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9zy6bq7g
2024-08-09 07:50:33,149 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,153 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36500
2024-08-09 07:50:33,153 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36500
2024-08-09 07:50:33,153 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-4
2024-08-09 07:50:33,153 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43330
2024-08-09 07:50:33,153 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,153 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,153 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,153 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,153 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0c75bp4f
2024-08-09 07:50:33,154 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,156 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33487
2024-08-09 07:50:33,156 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33487
2024-08-09 07:50:33,156 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-8
2024-08-09 07:50:33,156 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37009
2024-08-09 07:50:33,156 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,156 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,156 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,156 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,156 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ijsxt6q2
2024-08-09 07:50:33,156 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36129
2024-08-09 07:50:33,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36129
2024-08-09 07:50:33,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-3
2024-08-09 07:50:33,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37071
2024-08-09 07:50:33,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i5znz6j4
2024-08-09 07:50:33,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,161 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:45475
2024-08-09 07:50:33,161 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:45475
2024-08-09 07:50:33,161 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-7
2024-08-09 07:50:33,161 - distributed.worker - INFO -          dashboard at:           10.34.59.2:40523
2024-08-09 07:50:33,161 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,161 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,162 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,162 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,162 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zjqg8isr
2024-08-09 07:50:33,162 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,162 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:45491
2024-08-09 07:50:33,162 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:45491
2024-08-09 07:50:33,162 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-9
2024-08-09 07:50:33,162 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46401
2024-08-09 07:50:33,162 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,162 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,162 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,162 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,162 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0d10ae6y
2024-08-09 07:50:33,162 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,164 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37710
2024-08-09 07:50:33,164 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37710
2024-08-09 07:50:33,164 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-11
2024-08-09 07:50:33,164 - distributed.worker - INFO -          dashboard at:           10.34.59.2:45593
2024-08-09 07:50:33,164 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,164 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,164 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,164 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,164 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uv2f8lby
2024-08-09 07:50:33,164 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,166 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37390
2024-08-09 07:50:33,166 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37390
2024-08-09 07:50:33,166 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-1
2024-08-09 07:50:33,166 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44993
2024-08-09 07:50:33,166 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,167 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,167 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,167 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,167 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2by40gdw
2024-08-09 07:50:33,167 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,167 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43377
2024-08-09 07:50:33,168 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43377
2024-08-09 07:50:33,168 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-6
2024-08-09 07:50:33,168 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43969
2024-08-09 07:50:33,168 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,168 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,168 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,168 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,168 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2pxi037w
2024-08-09 07:50:33,168 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,169 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:42584
2024-08-09 07:50:33,169 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:42584
2024-08-09 07:50:33,169 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-14
2024-08-09 07:50:33,170 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43500
2024-08-09 07:50:33,170 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,170 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,170 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,170 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,170 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nu039t9n
2024-08-09 07:50:33,170 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,172 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37418
2024-08-09 07:50:33,173 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37418
2024-08-09 07:50:33,173 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-12
2024-08-09 07:50:33,173 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46002
2024-08-09 07:50:33,173 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,173 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,173 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,173 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,173 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tj055g95
2024-08-09 07:50:33,173 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,173 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35946
2024-08-09 07:50:33,173 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35946
2024-08-09 07:50:33,173 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-10
2024-08-09 07:50:33,173 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44588
2024-08-09 07:50:33,173 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,173 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,173 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,173 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,173 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-571byi4l
2024-08-09 07:50:33,174 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,174 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34551
2024-08-09 07:50:33,174 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34551
2024-08-09 07:50:33,174 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-13
2024-08-09 07:50:33,174 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43535
2024-08-09 07:50:33,175 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,175 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,176 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,176 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,176 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mcwe7jgl
2024-08-09 07:50:33,176 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,176 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:42237
2024-08-09 07:50:33,177 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:42237
2024-08-09 07:50:33,177 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-15
2024-08-09 07:50:33,177 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42743
2024-08-09 07:50:33,177 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,177 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,177 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,177 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,177 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-khho25ep
2024-08-09 07:50:33,177 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,179 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34573
2024-08-09 07:50:33,179 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34573
2024-08-09 07:50:33,179 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-5
2024-08-09 07:50:33,179 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42660
2024-08-09 07:50:33,179 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,179 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,179 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:50:33,179 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:50:33,179 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jl82ryhm
2024-08-09 07:50:33,179 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,526 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,526 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,526 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,527 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,527 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,527 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,527 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,528 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,528 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,528 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,528 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,529 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,529 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,529 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,531 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,531 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,531 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,537 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,538 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,538 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,538 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,538 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,539 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,539 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,539 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,541 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,541 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,541 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,542 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,546 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,546 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,546 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,546 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,547 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,547 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,547 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,547 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,548 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,548 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,548 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,549 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,549 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,549 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,551 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,551 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,551 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,558 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,558 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,559 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,559 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,563 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,564 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,564 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
2024-08-09 07:50:33,564 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:50:33,565 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:33290
2024-08-09 07:50:33,565 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:50:33,566 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:33290
slurmstepd: error: *** JOB 2331203 ON cl-node002 CANCELLED AT 2024-08-09T07:50:45 ***
2024-08-09 07:50:45,535 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33487. Reason: scheduler-close
2024-08-09 07:50:45,535 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38452. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37804. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36129. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37710. Reason: scheduler-close
2024-08-09 07:50:45,535 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36500. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43377. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:42584. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:42237. Reason: scheduler-close
2024-08-09 07:50:45,536 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35946. Reason: scheduler-close
2024-08-09 07:50:45,537 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34573. Reason: scheduler-close
2024-08-09 07:50:45,537 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:45475. Reason: scheduler-close
2024-08-09 07:50:45,537 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37418. Reason: scheduler-close
2024-08-09 07:50:45,538 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34551. Reason: scheduler-close
2024-08-09 07:50:45,538 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37390. Reason: scheduler-close
2024-08-09 07:50:45,538 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:45491. Reason: scheduler-close
2024-08-09 07:50:45,541 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43890'. Reason: scheduler-close
2024-08-09 07:50:45,545 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:33290; closing.
2024-08-09 07:50:45,545 - distributed.nanny - INFO - Worker closed
2024-08-09 07:50:45,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44943'. Reason: scheduler-close
2024-08-09 07:50:45,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36382'. Reason: scheduler-close
2024-08-09 07:50:45,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:37401'. Reason: scheduler-close
2024-08-09 07:50:45,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35504'. Reason: scheduler-close
2024-08-09 07:50:45,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45838'. Reason: scheduler-close
2024-08-09 07:50:45,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:34267'. Reason: scheduler-close
2024-08-09 07:50:45,550 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35042'. Reason: scheduler-close
2024-08-09 07:50:45,550 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46359'. Reason: scheduler-close
2024-08-09 07:50:45,550 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:33290; closing.
2024-08-09 07:50:45,550 - distributed.nanny - INFO - Worker closed
2024-08-09 07:50:45,551 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:33290; closing.
2024-08-09 07:50:45,551 - distributed.nanny - INFO - Worker closed
2024-08-09 07:50:45,551 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:33290; closing.
2024-08-09 07:50:45,551 - distributed.nanny - INFO - Worker closed
2024-08-09 07:50:45,550 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:42410 remote=tcp://10.34.59.1:33290>: Stream is closed
2024-08-09 07:50:45,550 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:42412 remote=tcp://10.34.59.1:33290>: Stream is closed
2024-08-09 07:50:45,550 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:42416 remote=tcp://10.34.59.1:33290>: Stream is closed
2024-08-09 07:50:45,551 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:42418 remote=tcp://10.34.59.1:33290>: Stream is closed
