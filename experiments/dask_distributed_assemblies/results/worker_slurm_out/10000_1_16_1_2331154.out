2024-08-09 07:24:14,667 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41853'
2024-08-09 07:24:14,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:34227'
2024-08-09 07:24:14,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:39610'
2024-08-09 07:24:14,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:38197'
2024-08-09 07:24:14,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33848'
2024-08-09 07:24:14,681 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44862'
2024-08-09 07:24:14,681 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46353'
2024-08-09 07:24:14,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36891'
2024-08-09 07:24:14,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:34769'
2024-08-09 07:24:14,691 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44683'
2024-08-09 07:24:14,692 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:40629'
2024-08-09 07:24:14,692 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33824'
2024-08-09 07:24:14,693 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33942'
2024-08-09 07:24:14,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:34582'
2024-08-09 07:24:14,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41752'
2024-08-09 07:24:14,695 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:37101'
2024-08-09 07:24:15,780 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41713
2024-08-09 07:24:15,780 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41713
2024-08-09 07:24:15,781 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 07:24:15,781 - distributed.worker - INFO -          dashboard at:           10.34.59.2:45046
2024-08-09 07:24:15,781 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,781 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,781 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,781 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,781 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2iwi6o8p
2024-08-09 07:24:15,781 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,785 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35563
2024-08-09 07:24:15,785 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35563
2024-08-09 07:24:15,785 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 07:24:15,785 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44853
2024-08-09 07:24:15,785 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,785 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,785 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,785 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,785 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b7786w3g
2024-08-09 07:24:15,785 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,787 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46255
2024-08-09 07:24:15,787 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46255
2024-08-09 07:24:15,787 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 07:24:15,787 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46662
2024-08-09 07:24:15,787 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,787 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,788 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,788 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d7ztyv57
2024-08-09 07:24:15,788 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,788 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:45288
2024-08-09 07:24:15,788 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:45288
2024-08-09 07:24:15,788 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 07:24:15,788 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34418
2024-08-09 07:24:15,788 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,788 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,789 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,789 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,789 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4fzfms8p
2024-08-09 07:24:15,789 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,794 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37607
2024-08-09 07:24:15,794 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37607
2024-08-09 07:24:15,794 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 07:24:15,794 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41014
2024-08-09 07:24:15,794 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,794 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,794 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,794 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,794 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-j47bpp1z
2024-08-09 07:24:15,794 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,794 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38946
2024-08-09 07:24:15,795 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38946
2024-08-09 07:24:15,795 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 07:24:15,795 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34737
2024-08-09 07:24:15,795 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,795 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,795 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,795 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,795 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3v3uszbx
2024-08-09 07:24:15,795 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,796 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43108
2024-08-09 07:24:15,796 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43108
2024-08-09 07:24:15,797 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-9
2024-08-09 07:24:15,797 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42266
2024-08-09 07:24:15,797 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,797 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,797 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,797 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,797 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u30zgrv0
2024-08-09 07:24:15,797 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,800 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33732
2024-08-09 07:24:15,800 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33732
2024-08-09 07:24:15,800 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 07:24:15,801 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42763
2024-08-09 07:24:15,801 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,801 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,801 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,801 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,801 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-js3f3kko
2024-08-09 07:24:15,801 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,801 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46736
2024-08-09 07:24:15,801 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46736
2024-08-09 07:24:15,801 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-11
2024-08-09 07:24:15,801 - distributed.worker - INFO -          dashboard at:           10.34.59.2:45000
2024-08-09 07:24:15,801 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,801 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,801 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,801 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,801 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-roxq520z
2024-08-09 07:24:15,801 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,809 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43351
2024-08-09 07:24:15,809 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43351
2024-08-09 07:24:15,809 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-14
2024-08-09 07:24:15,809 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44706
2024-08-09 07:24:15,809 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,809 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,809 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,809 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,809 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cgody7ya
2024-08-09 07:24:15,809 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,814 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33562
2024-08-09 07:24:15,814 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33562
2024-08-09 07:24:15,814 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-12
2024-08-09 07:24:15,814 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34509
2024-08-09 07:24:15,814 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,814 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,814 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,814 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,814 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2r9g6w51
2024-08-09 07:24:15,814 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35410
2024-08-09 07:24:15,814 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,814 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35410
2024-08-09 07:24:15,814 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-10
2024-08-09 07:24:15,814 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38096
2024-08-09 07:24:15,814 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,814 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:44873
2024-08-09 07:24:15,814 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,814 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,814 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:44873
2024-08-09 07:24:15,814 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,815 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-8
2024-08-09 07:24:15,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0e5h6o70
2024-08-09 07:24:15,815 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44599
2024-08-09 07:24:15,815 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,815 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,815 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,815 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,815 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,815 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z83t3ih9
2024-08-09 07:24:15,815 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,817 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46476
2024-08-09 07:24:15,817 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46476
2024-08-09 07:24:15,817 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 07:24:15,817 - distributed.worker - INFO -          dashboard at:           10.34.59.2:35322
2024-08-09 07:24:15,817 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,817 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,817 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,817 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,817 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xyzbrzjh
2024-08-09 07:24:15,817 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,818 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41921
2024-08-09 07:24:15,818 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41921
2024-08-09 07:24:15,819 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-13
2024-08-09 07:24:15,819 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37125
2024-08-09 07:24:15,819 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,819 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,819 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,819 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,819 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0qn36bhk
2024-08-09 07:24:15,819 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,822 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38801
2024-08-09 07:24:15,823 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38801
2024-08-09 07:24:15,823 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-15
2024-08-09 07:24:15,823 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34818
2024-08-09 07:24:15,823 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42172
2024-08-09 07:24:15,823 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:15,823 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:15,823 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:15,823 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dqzoqs6a
2024-08-09 07:24:15,823 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,159 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,159 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,161 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,161 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,161 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,167 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,168 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,168 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,168 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,168 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,169 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,168 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,169 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,169 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,169 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,169 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,169 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,170 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,170 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,170 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,170 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,175 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,175 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,176 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,187 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,188 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,188 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,188 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,188 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,189 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,189 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,191 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,191 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,191 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,195 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,195 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,195 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,197 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,197 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,198 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,202 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,203 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,203 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,203 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,204 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,204 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,210 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,211 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,211 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,211 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:16,212 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:16,213 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42172
2024-08-09 07:24:16,213 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:16,213 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42172
2024-08-09 07:24:19,582 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 07:24:19,593 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 07:24:20,055 - distributed.worker.memory - WARNING - Worker is at 8% memory usage. Resuming worker. Process memory: 171.34 MiB -- Worker memory limit: 1.86 GiB
slurmstepd: error: *** JOB 2331154 ON cl-node002 CANCELLED AT 2024-08-09T07:24:36 ***
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41713. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35563. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43108. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38946. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46255. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46736. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41921. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35410. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33562. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:45288. Reason: scheduler-close
2024-08-09 07:24:36,203 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37607. Reason: scheduler-close
2024-08-09 07:24:36,204 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:44873. Reason: scheduler-close
2024-08-09 07:24:36,205 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38801. Reason: scheduler-close
2024-08-09 07:24:36,205 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43351. Reason: scheduler-close
2024-08-09 07:24:36,205 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33732. Reason: scheduler-close
2024-08-09 07:24:36,205 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46476. Reason: scheduler-close
2024-08-09 07:24:36,205 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47402 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47402 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,206 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47424 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47424 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,205 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47400 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47400 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,206 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47412 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47412 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,207 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47420 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47420 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,207 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47418 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47418 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,209 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33848'. Reason: scheduler-close
2024-08-09 07:24:36,210 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:39610'. Reason: scheduler-close
2024-08-09 07:24:36,212 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,213 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,211 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47408 remote=tcp://10.34.59.1:42172>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:47408 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,213 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,213 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,214 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44683'. Reason: scheduler-close
2024-08-09 07:24:36,214 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33824'. Reason: scheduler-close
2024-08-09 07:24:36,214 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:47448 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,215 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:40629'. Reason: scheduler-close
2024-08-09 07:24:36,215 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46353'. Reason: scheduler-close
2024-08-09 07:24:36,215 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:34582'. Reason: scheduler-close
2024-08-09 07:24:36,215 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:47450 remote=tcp://10.34.59.1:42172>: Stream is closed
2024-08-09 07:24:36,216 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:34227'. Reason: scheduler-close
2024-08-09 07:24:36,216 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33942'. Reason: scheduler-close
2024-08-09 07:24:36,215 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 140, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.2:47452 remote=tcp://10.34.59.1:42172>: ConnectionResetError: [Errno 104] Connection reset by peer
2024-08-09 07:24:36,216 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,216 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,217 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,217 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,217 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,217 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,217 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,218 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,218 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,218 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,218 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,218 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,219 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,219 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,219 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41853'. Reason: scheduler-close
2024-08-09 07:24:36,220 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:38197'. Reason: scheduler-close
2024-08-09 07:24:36,220 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:37101'. Reason: scheduler-close
2024-08-09 07:24:36,220 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41752'. Reason: scheduler-close
2024-08-09 07:24:36,221 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36891'. Reason: scheduler-close
2024-08-09 07:24:36,221 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:34769'. Reason: scheduler-close
2024-08-09 07:24:36,222 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,222 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,222 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,222 - distributed.nanny - INFO - Worker closed
2024-08-09 07:24:36,222 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42172; closing.
2024-08-09 07:24:36,223 - distributed.nanny - INFO - Worker closed
