2024-08-09 07:24:48,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36279'
2024-08-09 07:24:48,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42462'
2024-08-09 07:24:48,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44881'
2024-08-09 07:24:48,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44181'
2024-08-09 07:24:48,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33359'
2024-08-09 07:24:48,168 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:42957'
2024-08-09 07:24:48,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45061'
2024-08-09 07:24:48,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43979'
2024-08-09 07:24:48,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41527'
2024-08-09 07:24:48,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:40233'
2024-08-09 07:24:48,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45373'
2024-08-09 07:24:48,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46291'
2024-08-09 07:24:48,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:38747'
2024-08-09 07:24:48,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36250'
2024-08-09 07:24:48,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45761'
2024-08-09 07:24:48,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43977'
2024-08-09 07:24:48,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-js3f3kko', purging
2024-08-09 07:24:48,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-xyzbrzjh', purging
2024-08-09 07:24:48,778 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cgody7ya', purging
2024-08-09 07:24:49,322 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:42354
2024-08-09 07:24:49,322 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:44492
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:42354
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46044
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:42615
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:44492
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41107
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46044
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:42615
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34394
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41107
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42521
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-15
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-13
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39002
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34711
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41044
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-8
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39708
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34394
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38890
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34088
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:46273
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37480
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39002
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34711
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-12
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37364
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39708
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41670
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:32954
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34088
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:46273
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:44457
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-9
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38761
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38212
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:32954
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:44457
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44636
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46439
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41670
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38761
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41726
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-alfx_vvd
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44879
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42302
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-10
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ql2k65uh
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-14
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pi8y42l0
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46381
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41544
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o25ghl4y
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42712
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41491
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-0rpjuqhs
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-22gwsfat
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-39z6q1y5
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1_a92imw
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nv3c99jj
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xz97pnrx
2024-08-09 07:24:49,323 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-orer8q3j
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lqbd5y6l
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1my199yk
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vrkl86nd
2024-08-09 07:24:49,323 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-52cszttr
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,323 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,324 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35563
2024-08-09 07:24:49,324 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35563
2024-08-09 07:24:49,324 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-11
2024-08-09 07:24:49,324 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41752
2024-08-09 07:24:49,324 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,324 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,324 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:24:49,324 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:24:49,324 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-g2ink5ey
2024-08-09 07:24:49,324 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,782 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,782 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,782 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,783 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,783 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,783 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,784 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,784 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,784 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,784 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,785 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,785 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,785 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,786 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,786 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,786 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,787 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,787 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,787 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,787 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,787 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,788 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,788 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,788 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,788 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,788 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,789 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,789 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,789 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,789 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,790 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,790 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,790 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,791 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,791 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,791 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,791 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,791 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,791 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,792 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,792 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,792 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,793 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,793 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,796 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,796 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,796 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,797 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,797 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,798 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:49,798 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:24:49,798 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:41814
2024-08-09 07:24:49,798 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:24:49,799 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:41814
2024-08-09 07:24:53,046 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 07:24:53,047 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 07:24:53,158 - distributed.worker.memory - WARNING - Worker is at 37% memory usage. Resuming worker. Process memory: 713.78 MiB -- Worker memory limit: 1.86 GiB
slurmstepd: error: *** JOB 2331155 ON cl-node002 CANCELLED AT 2024-08-09T07:25:09 ***
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38761. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:44457. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41107. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46044. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:42354. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:42615. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34711. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:44492. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:32954. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34394. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:46273. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39708. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34088. Reason: scheduler-close
2024-08-09 07:25:09,771 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39002. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41670. Reason: scheduler-close
2024-08-09 07:25:09,772 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35563. Reason: scheduler-close
2024-08-09 07:25:09,773 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33524 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33524 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,774 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33530 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33530 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33542 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33542 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33538 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33538 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,774 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33534 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33534 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33540 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33540 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33554 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33554 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33552 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33552 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,775 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33546 remote=tcp://10.34.59.1:41814>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:33546 remote=tcp://10.34.59.1:41814>: Stream is closed
2024-08-09 07:25:09,776 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45373'. Reason: scheduler-close
2024-08-09 07:25:09,779 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45761'. Reason: scheduler-close
2024-08-09 07:25:09,779 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41527'. Reason: scheduler-close
2024-08-09 07:25:09,779 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,779 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,782 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,782 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,782 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,782 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,785 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43977'. Reason: scheduler-close
2024-08-09 07:25:09,785 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36279'. Reason: scheduler-close
2024-08-09 07:25:09,785 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:42462'. Reason: scheduler-close
2024-08-09 07:25:09,786 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45061'. Reason: scheduler-close
2024-08-09 07:25:09,786 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44181'. Reason: scheduler-close
2024-08-09 07:25:09,786 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36250'. Reason: scheduler-close
2024-08-09 07:25:09,787 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:38747'. Reason: scheduler-close
2024-08-09 07:25:09,787 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:42957'. Reason: scheduler-close
2024-08-09 07:25:09,787 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,787 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,787 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,787 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,788 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43979'. Reason: scheduler-close
2024-08-09 07:25:09,788 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,788 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:40233'. Reason: scheduler-close
2024-08-09 07:25:09,788 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,788 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,788 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,788 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33359'. Reason: scheduler-close
2024-08-09 07:25:09,789 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46291'. Reason: scheduler-close
2024-08-09 07:25:09,789 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,789 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,789 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44881'. Reason: scheduler-close
2024-08-09 07:25:09,790 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,790 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,790 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,790 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,790 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,790 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,790 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,790 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,791 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,789 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils.py", line 1961, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 445, in wait_for
    return fut.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 559, in connect
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 140, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x2b8ea3d0ded0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1564, in _connect
    comm = await connect(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/opt/apps/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/asyncio/tasks.py", line 605, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1674, in connect
    return connect_attempt.result()
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1392, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1676, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-08-09 07:25:09,791 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,791 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,791 - distributed.nanny - INFO - Worker closed
2024-08-09 07:25:09,792 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:41814; closing.
2024-08-09 07:25:09,792 - distributed.nanny - INFO - Worker closed
