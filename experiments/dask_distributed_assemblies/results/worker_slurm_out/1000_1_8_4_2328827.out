2024-08-09 04:00:37,010 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43550'
2024-08-09 04:00:37,011 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41452'
2024-08-09 04:00:37,017 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36863'
2024-08-09 04:00:37,020 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43603'
2024-08-09 04:00:37,020 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43181'
2024-08-09 04:00:37,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35696'
2024-08-09 04:00:37,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44246'
2024-08-09 04:00:37,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46008'
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:42176
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34947
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39949
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43155
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:42176
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34947
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39949
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43155
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36253
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38542
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36941
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42352
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:32788
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:44785
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:40374
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36253
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38542
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36941
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38762
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:44785
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:36012
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:40408
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42995
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -          dashboard at:           10.34.59.2:33548
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rn5tofu5
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cb6fc186
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e2gpxecm
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2e3awkdc
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO -               Threads:                          1
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1nf851qb
2024-08-09 04:00:38,159 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,159 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-txfukphg
2024-08-09 04:00:38,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_b4jmgrn
2024-08-09 04:00:38,160 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 04:00:38,160 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,160 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,160 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d1virno9
2024-08-09 04:00:38,160 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,160 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,583 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,583 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,584 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,584 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,584 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,585 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,585 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,585 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,585 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,585 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,586 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,586 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,586 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,594 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,594 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,594 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,595 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,595 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,595 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,595 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,595 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,596 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,596 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,596 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,596 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 04:00:38,596 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:38,597 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:46269
2024-08-09 04:00:38,597 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 04:00:38,597 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:46269
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36253. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39949. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:42176. Reason: scheduler-close
slurmstepd: error: *** JOB 2328827 ON cl-node002 CANCELLED AT 2024-08-09T04:00:47 ***
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36941. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38542. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34947. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:44785. Reason: scheduler-close
2024-08-09 04:00:47,413 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43155. Reason: scheduler-close
2024-08-09 04:00:47,414 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55913 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55913 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,414 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55920 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55920 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55922 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55922 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55924 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55924 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55916 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55916 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55926 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55926 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,415 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55912 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55912 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,416 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55918 remote=tcp://10.34.59.1:46269>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:55918 remote=tcp://10.34.59.1:46269>: Stream is closed
2024-08-09 04:00:47,418 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36863'. Reason: scheduler-close
2024-08-09 04:00:47,418 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41452'. Reason: scheduler-close
2024-08-09 04:00:47,419 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44246'. Reason: scheduler-close
2024-08-09 04:00:47,419 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46008'. Reason: scheduler-close
2024-08-09 04:00:47,419 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43550'. Reason: scheduler-close
2024-08-09 04:00:47,420 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43603'. Reason: scheduler-close
2024-08-09 04:00:47,420 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,420 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,420 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,420 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,421 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43181'. Reason: scheduler-close
2024-08-09 04:00:47,421 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,421 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,421 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35696'. Reason: scheduler-close
2024-08-09 04:00:47,421 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,422 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,422 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,422 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,423 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,423 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,424 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,424 - distributed.nanny - INFO - Worker closed
2024-08-09 04:00:47,424 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:46269; closing.
2024-08-09 04:00:47,425 - distributed.nanny - INFO - Worker closed
