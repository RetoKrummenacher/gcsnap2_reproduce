2024-08-09 07:51:22,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:36047'
2024-08-09 07:51:22,635 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42530'
2024-08-09 07:51:22,635 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:37288'
2024-08-09 07:51:22,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:39148'
2024-08-09 07:51:22,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:44189'
2024-08-09 07:51:22,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:32905'
2024-08-09 07:51:22,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:45155'
2024-08-09 07:51:22,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:39397'
2024-08-09 07:51:22,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:35463'
2024-08-09 07:51:22,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:35343'
2024-08-09 07:51:22,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:44797'
2024-08-09 07:51:22,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42434'
2024-08-09 07:51:22,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:35331'
2024-08-09 07:51:22,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:40463'
2024-08-09 07:51:22,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:46277'
2024-08-09 07:51:22,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:45395'
2024-08-09 07:51:23,764 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:45524
2024-08-09 07:51:23,765 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:45524
2024-08-09 07:51:23,765 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-15
2024-08-09 07:51:23,765 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:45895
2024-08-09 07:51:23,765 - distributed.worker - INFO -          dashboard at:           10.34.59.4:45719
2024-08-09 07:51:23,765 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,765 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:45895
2024-08-09 07:51:23,765 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,765 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,765 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-0
2024-08-09 07:51:23,765 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,765 - distributed.worker - INFO -          dashboard at:           10.34.59.4:42268
2024-08-09 07:51:23,765 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c_ip_7f5
2024-08-09 07:51:23,765 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,765 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,765 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,765 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,765 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,765 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n6hy2gor
2024-08-09 07:51:23,765 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,765 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:44656
2024-08-09 07:51:23,766 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:44656
2024-08-09 07:51:23,766 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-2
2024-08-09 07:51:23,766 - distributed.worker - INFO -          dashboard at:           10.34.59.4:41254
2024-08-09 07:51:23,766 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,766 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,766 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,766 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,766 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ylpd0r8v
2024-08-09 07:51:23,766 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,769 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:38683
2024-08-09 07:51:23,769 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:38683
2024-08-09 07:51:23,769 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-1
2024-08-09 07:51:23,769 - distributed.worker - INFO -          dashboard at:           10.34.59.4:42086
2024-08-09 07:51:23,769 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,769 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,769 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,769 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,769 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8r1dd_72
2024-08-09 07:51:23,769 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:46452
2024-08-09 07:51:23,769 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,769 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:46452
2024-08-09 07:51:23,769 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-3
2024-08-09 07:51:23,769 - distributed.worker - INFO -          dashboard at:           10.34.59.4:39325
2024-08-09 07:51:23,769 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,769 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,769 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,769 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,769 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-na_u_8ib
2024-08-09 07:51:23,769 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,771 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:44569
2024-08-09 07:51:23,771 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:44569
2024-08-09 07:51:23,771 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-9
2024-08-09 07:51:23,771 - distributed.worker - INFO -          dashboard at:           10.34.59.4:44722
2024-08-09 07:51:23,771 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,771 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,771 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:43659
2024-08-09 07:51:23,772 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8qj247wg
2024-08-09 07:51:23,772 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:43659
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42597
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-6
2024-08-09 07:51:23,772 - distributed.worker - INFO -          dashboard at:           10.34.59.4:44197
2024-08-09 07:51:23,772 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42597
2024-08-09 07:51:23,772 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,772 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-5
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -          dashboard at:           10.34.59.4:41050
2024-08-09 07:51:23,772 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,772 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,772 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-56mmwqa1
2024-08-09 07:51:23,772 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,772 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kankinde
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:34822
2024-08-09 07:51:23,772 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:34822
2024-08-09 07:51:23,772 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-10
2024-08-09 07:51:23,772 - distributed.worker - INFO -          dashboard at:           10.34.59.4:41749
2024-08-09 07:51:23,772 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,772 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,772 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,773 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,772 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:44916
2024-08-09 07:51:23,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fdcxyb0f
2024-08-09 07:51:23,773 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:44916
2024-08-09 07:51:23,773 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,773 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-11
2024-08-09 07:51:23,773 - distributed.worker - INFO -          dashboard at:           10.34.59.4:45159
2024-08-09 07:51:23,773 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,773 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,773 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,773 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rcfrxgx5
2024-08-09 07:51:23,773 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:34202
2024-08-09 07:51:23,773 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,774 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:34202
2024-08-09 07:51:23,775 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42850
2024-08-09 07:51:23,775 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-12
2024-08-09 07:51:23,775 - distributed.worker - INFO -          dashboard at:           10.34.59.4:41136
2024-08-09 07:51:23,775 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42850
2024-08-09 07:51:23,775 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42564
2024-08-09 07:51:23,775 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,775 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-7
2024-08-09 07:51:23,775 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:34170
2024-08-09 07:51:23,775 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,775 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42564
2024-08-09 07:51:23,775 - distributed.worker - INFO -          dashboard at:           10.34.59.4:33219
2024-08-09 07:51:23,775 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,775 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:34170
2024-08-09 07:51:23,775 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,775 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-8
2024-08-09 07:51:23,775 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,775 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-4
2024-08-09 07:51:23,775 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,775 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v_87r2lc
2024-08-09 07:51:23,775 - distributed.worker - INFO -          dashboard at:           10.34.59.4:34523
2024-08-09 07:51:23,775 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,775 - distributed.worker - INFO -          dashboard at:           10.34.59.4:38487
2024-08-09 07:51:23,775 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,775 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,775 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,776 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,776 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,776 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,776 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,776 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oqw8yhvz
2024-08-09 07:51:23,776 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,776 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,776 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,776 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p5hccn5o
2024-08-09 07:51:23,776 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,776 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-i0ttf57e
2024-08-09 07:51:23,776 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,776 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,791 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:39541
2024-08-09 07:51:23,791 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:44639
2024-08-09 07:51:23,791 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:39541
2024-08-09 07:51:23,791 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:44639
2024-08-09 07:51:23,791 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-13
2024-08-09 07:51:23,791 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-14
2024-08-09 07:51:23,791 - distributed.worker - INFO -          dashboard at:           10.34.59.4:38759
2024-08-09 07:51:23,791 - distributed.worker - INFO -          dashboard at:           10.34.59.4:46093
2024-08-09 07:51:23,791 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,791 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,791 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:44673
2024-08-09 07:51:23,791 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,791 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,791 - distributed.worker - INFO -               Threads:                          1
2024-08-09 07:51:23,791 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,791 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_snzk1q6
2024-08-09 07:51:23,791 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 07:51:23,792 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l69rzc9n
2024-08-09 07:51:23,792 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:23,792 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,150 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,150 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,151 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,151 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,151 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,151 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,152 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,152 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,152 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,152 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,152 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,153 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,153 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,153 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,154 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,154 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,154 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,154 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,155 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,156 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,156 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,156 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,156 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,157 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,157 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,157 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,157 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,158 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,158 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,158 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,159 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,159 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,159 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,159 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,159 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,160 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,160 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,160 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,160 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,161 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,161 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,161 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,171 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,171 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,171 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,171 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,172 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,172 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,172 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,178 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,178 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,179 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 07:51:24,179 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
2024-08-09 07:51:24,179 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:44673
2024-08-09 07:51:24,180 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 07:51:24,180 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:44673
slurmstepd: error: *** JOB 2331208 ON cl-node004 CANCELLED AT 2024-08-09T07:51:36 ***
2024-08-09 07:51:36,178 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42597. Reason: scheduler-close
2024-08-09 07:51:36,178 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:45895. Reason: scheduler-close
2024-08-09 07:51:36,178 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:45524. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42564. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:44916. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:34822. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:46452. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:34202. Reason: scheduler-close
2024-08-09 07:51:36,178 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:44569. Reason: scheduler-close
2024-08-09 07:51:36,178 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:44656. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:38683. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:43659. Reason: scheduler-close
2024-08-09 07:51:36,179 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42850. Reason: scheduler-close
2024-08-09 07:51:36,180 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:44639. Reason: scheduler-close
2024-08-09 07:51:36,180 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:39541. Reason: scheduler-close
2024-08-09 07:51:36,181 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:34170. Reason: scheduler-close
2024-08-09 07:51:36,183 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:46598 remote=tcp://10.34.59.1:44673>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:46598 remote=tcp://10.34.59.1:44673>: Stream is closed
2024-08-09 07:51:36,189 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:45155'. Reason: scheduler-close
2024-08-09 07:51:36,190 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42530'. Reason: scheduler-close
2024-08-09 07:51:36,190 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:35343'. Reason: scheduler-close
2024-08-09 07:51:36,191 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:36047'. Reason: scheduler-close
2024-08-09 07:51:36,191 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:35331'. Reason: scheduler-close
2024-08-09 07:51:36,192 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42434'. Reason: scheduler-close
2024-08-09 07:51:36,192 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:44189'. Reason: scheduler-close
2024-08-09 07:51:36,192 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,192 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,192 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:40463'. Reason: scheduler-close
2024-08-09 07:51:36,193 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:39397'. Reason: scheduler-close
2024-08-09 07:51:36,193 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:44797'. Reason: scheduler-close
2024-08-09 07:51:36,193 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,193 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,193 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,193 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,194 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,194 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,194 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,194 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,194 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,194 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,195 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,195 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,195 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,196 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,196 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,196 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,196 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:39148'. Reason: scheduler-close
2024-08-09 07:51:36,197 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:37288'. Reason: scheduler-close
2024-08-09 07:51:36,197 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,197 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,197 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:35463'. Reason: scheduler-close
2024-08-09 07:51:36,198 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:46277'. Reason: scheduler-close
2024-08-09 07:51:36,198 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:45395'. Reason: scheduler-close
2024-08-09 07:51:36,199 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:32905'. Reason: scheduler-close
2024-08-09 07:51:36,199 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.4:46632 remote=tcp://10.34.59.1:44673>: Stream is closed
2024-08-09 07:51:36,201 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,201 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,201 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,201 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,201 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,201 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,201 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,201 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,201 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 452, in retry_operation
    return await retry(
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/utils_comm.py", line 431, in retry
    return await coro()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1395, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/core.py", line 1154, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 236, in read
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.34.59.4:46634 remote=tcp://10.34.59.1:44673>: Stream is closed
2024-08-09 07:51:36,203 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,203 - distributed.nanny - INFO - Worker closed
2024-08-09 07:51:36,204 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:44673; closing.
2024-08-09 07:51:36,204 - distributed.nanny - INFO - Worker closed
