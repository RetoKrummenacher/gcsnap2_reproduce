2024-08-09 06:14:51,876 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35485'
2024-08-09 06:14:51,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:39351'
2024-08-09 06:14:51,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:33848'
2024-08-09 06:14:51,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:38076'
2024-08-09 06:14:51,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35900'
2024-08-09 06:14:51,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:41887'
2024-08-09 06:14:51,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:44702'
2024-08-09 06:14:51,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43515'
2024-08-09 06:14:51,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:46718'
2024-08-09 06:14:51,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45231'
2024-08-09 06:14:51,903 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:35129'
2024-08-09 06:14:51,903 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:39401'
2024-08-09 06:14:51,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:43805'
2024-08-09 06:14:51,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:45154'
2024-08-09 06:14:51,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:37409'
2024-08-09 06:14:51,905 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.2:36449'
2024-08-09 06:14:52,992 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:36208
2024-08-09 06:14:52,992 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39043
2024-08-09 06:14:52,992 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:36208
2024-08-09 06:14:52,992 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-08-09 06:14:52,992 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39043
2024-08-09 06:14:52,992 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-08-09 06:14:52,992 - distributed.worker - INFO -          dashboard at:           10.34.59.2:32851
2024-08-09 06:14:52,992 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:52,992 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42755
2024-08-09 06:14:52,992 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,992 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:52,992 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:52,992 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,992 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:52,992 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:52,992 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-34t_r7a3
2024-08-09 06:14:52,992 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:52,992 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hd9y00f1
2024-08-09 06:14:52,992 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,992 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,996 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:33114
2024-08-09 06:14:52,996 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:33114
2024-08-09 06:14:52,996 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-08-09 06:14:52,996 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:41644
2024-08-09 06:14:52,996 - distributed.worker - INFO -          dashboard at:           10.34.59.2:35865
2024-08-09 06:14:52,996 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:41644
2024-08-09 06:14:52,996 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:52,996 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-08-09 06:14:52,996 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,996 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:52,996 - distributed.worker - INFO -          dashboard at:           10.34.59.2:42775
2024-08-09 06:14:52,996 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:52,996 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:52,997 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y1bdg12g
2024-08-09 06:14:52,997 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,997 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:52,997 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:52,997 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:52,997 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-v6rwpxsi
2024-08-09 06:14:52,997 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,001 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35174
2024-08-09 06:14:53,001 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35174
2024-08-09 06:14:53,001 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-5
2024-08-09 06:14:53,001 - distributed.worker - INFO -          dashboard at:           10.34.59.2:41028
2024-08-09 06:14:53,001 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,001 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,001 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,001 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,001 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-89alb7a5
2024-08-09 06:14:53,001 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,001 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:40272
2024-08-09 06:14:53,001 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:40272
2024-08-09 06:14:53,001 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-4
2024-08-09 06:14:53,002 - distributed.worker - INFO -          dashboard at:           10.34.59.2:39650
2024-08-09 06:14:53,002 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,002 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,002 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,002 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,002 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h42wp9kn
2024-08-09 06:14:53,002 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,004 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:43394
2024-08-09 06:14:53,004 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:43394
2024-08-09 06:14:53,004 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-6
2024-08-09 06:14:53,004 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38548
2024-08-09 06:14:53,004 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35577
2024-08-09 06:14:53,004 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,004 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,004 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35577
2024-08-09 06:14:53,004 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,004 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-7
2024-08-09 06:14:53,004 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,004 - distributed.worker - INFO -          dashboard at:           10.34.59.2:35051
2024-08-09 06:14:53,004 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jmtrgw9u
2024-08-09 06:14:53,004 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,004 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,004 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,004 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,004 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,004 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6ninnova
2024-08-09 06:14:53,004 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,007 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39505
2024-08-09 06:14:53,008 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39505
2024-08-09 06:14:53,008 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-8
2024-08-09 06:14:53,008 - distributed.worker - INFO -          dashboard at:           10.34.59.2:44188
2024-08-09 06:14:53,008 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,008 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,008 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,008 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,008 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n7kddlsz
2024-08-09 06:14:53,008 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,011 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:39542
2024-08-09 06:14:53,012 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:39542
2024-08-09 06:14:53,012 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-9
2024-08-09 06:14:53,012 - distributed.worker - INFO -          dashboard at:           10.34.59.2:43270
2024-08-09 06:14:53,012 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,012 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,012 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,012 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,012 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-nvhy4d63
2024-08-09 06:14:53,012 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,021 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:40381
2024-08-09 06:14:53,021 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:40381
2024-08-09 06:14:53,021 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-12
2024-08-09 06:14:53,021 - distributed.worker - INFO -          dashboard at:           10.34.59.2:46633
2024-08-09 06:14:53,021 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:34482
2024-08-09 06:14:53,021 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,021 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,021 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:34482
2024-08-09 06:14:53,021 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,021 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-11
2024-08-09 06:14:53,021 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-p_tjwrbe
2024-08-09 06:14:53,021 - distributed.worker - INFO -          dashboard at:           10.34.59.2:37565
2024-08-09 06:14:53,021 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,021 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,021 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,021 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,021 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-admdmd66
2024-08-09 06:14:53,021 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,022 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:35414
2024-08-09 06:14:53,023 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:38303
2024-08-09 06:14:53,023 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:35414
2024-08-09 06:14:53,024 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:38303
2024-08-09 06:14:53,024 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-14
2024-08-09 06:14:53,024 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-13
2024-08-09 06:14:53,024 - distributed.worker - INFO -          dashboard at:           10.34.59.2:40421
2024-08-09 06:14:53,024 - distributed.worker - INFO -          dashboard at:           10.34.59.2:39816
2024-08-09 06:14:53,024 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,024 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,024 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,024 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,024 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,024 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,024 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,024 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,024 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d_z6z12g
2024-08-09 06:14:53,024 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h3y_t4l9
2024-08-09 06:14:53,024 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,024 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,024 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:45477
2024-08-09 06:14:53,025 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:45477
2024-08-09 06:14:53,025 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-15
2024-08-09 06:14:53,025 - distributed.worker - INFO -          dashboard at:           10.34.59.2:34662
2024-08-09 06:14:53,025 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,025 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,025 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,025 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,025 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6rubzimg
2024-08-09 06:14:53,025 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,037 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.2:37404
2024-08-09 06:14:53,037 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.2:37404
2024-08-09 06:14:53,037 - distributed.worker - INFO -           Worker name:          SLURMCluster-0-10
2024-08-09 06:14:53,037 - distributed.worker - INFO -          dashboard at:           10.34.59.2:38329
2024-08-09 06:14:53,037 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,037 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,037 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:53,037 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:53,037 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-e9olu4f3
2024-08-09 06:14:53,037 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,370 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,371 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,371 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,371 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,371 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,372 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,372 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,372 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,374 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,375 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,375 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,375 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,376 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,376 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,376 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,377 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,377 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,378 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,378 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,378 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,378 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,378 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,383 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,383 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,384 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,384 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,384 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,384 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,384 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,385 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,400 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,401 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,401 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,401 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,401 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,402 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,402 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,403 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,405 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,406 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,406 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,406 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,422 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,422 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,423 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,423 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,426 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,426 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,427 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,427 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,427 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,428 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,428 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,428 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,429 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,429 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:53,429 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
2024-08-09 06:14:53,429 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:42841
2024-08-09 06:14:53,430 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:53,430 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:42841
slurmstepd: error: *** JOB 2330430 ON cl-node002 CANCELLED AT 2024-08-09T06:15:03 ***
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:36208. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39043. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:40272. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:41644. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39505. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:39542. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:33114. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35174. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:43394. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:37404. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35577. Reason: scheduler-close
2024-08-09 06:15:03,154 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:34482. Reason: scheduler-close
2024-08-09 06:15:03,155 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:40381. Reason: scheduler-close
2024-08-09 06:15:03,156 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:38303. Reason: scheduler-close
2024-08-09 06:15:03,157 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:35414. Reason: scheduler-close
2024-08-09 06:15:03,157 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.2:45477. Reason: scheduler-close
2024-08-09 06:15:03,157 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58104 remote=tcp://10.34.59.1:42841>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58104 remote=tcp://10.34.59.1:42841>: Stream is closed
2024-08-09 06:15:03,157 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58110 remote=tcp://10.34.59.1:42841>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58110 remote=tcp://10.34.59.1:42841>: Stream is closed
2024-08-09 06:15:03,158 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58108 remote=tcp://10.34.59.1:42841>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58108 remote=tcp://10.34.59.1:42841>: Stream is closed
2024-08-09 06:15:03,159 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58112 remote=tcp://10.34.59.1:42841>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.2:58112 remote=tcp://10.34.59.1:42841>: Stream is closed
2024-08-09 06:15:03,162 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:39351'. Reason: scheduler-close
2024-08-09 06:15:03,162 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:38076'. Reason: scheduler-close
2024-08-09 06:15:03,163 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35900'. Reason: scheduler-close
2024-08-09 06:15:03,163 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35485'. Reason: scheduler-close
2024-08-09 06:15:03,163 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:46718'. Reason: scheduler-close
2024-08-09 06:15:03,164 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45231'. Reason: scheduler-close
2024-08-09 06:15:03,164 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:41887'. Reason: scheduler-close
2024-08-09 06:15:03,164 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:35129'. Reason: scheduler-close
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:33848'. Reason: scheduler-close
2024-08-09 06:15:03,165 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,165 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43515'. Reason: scheduler-close
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,165 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,165 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,165 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:44702'. Reason: scheduler-close
2024-08-09 06:15:03,166 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,166 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,166 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,167 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,167 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,167 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:39401'. Reason: scheduler-close
2024-08-09 06:15:03,167 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,168 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,168 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,169 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,169 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,169 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,169 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,169 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:43805'. Reason: scheduler-close
2024-08-09 06:15:03,169 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,170 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,170 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:45154'. Reason: scheduler-close
2024-08-09 06:15:03,170 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:37409'. Reason: scheduler-close
2024-08-09 06:15:03,170 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.2:36449'. Reason: scheduler-close
2024-08-09 06:15:03,171 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,171 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,173 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,173 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,173 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,173 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,173 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,173 - distributed.nanny - INFO - Worker closed
2024-08-09 06:15:03,174 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:42841; closing.
2024-08-09 06:15:03,174 - distributed.nanny - INFO - Worker closed
