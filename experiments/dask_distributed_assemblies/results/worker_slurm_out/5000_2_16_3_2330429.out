2024-08-09 06:14:28,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:46878'
2024-08-09 06:14:28,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:45022'
2024-08-09 06:14:28,580 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42790'
2024-08-09 06:14:28,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:39883'
2024-08-09 06:14:28,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:46836'
2024-08-09 06:14:28,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42308'
2024-08-09 06:14:28,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:40106'
2024-08-09 06:14:28,589 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42275'
2024-08-09 06:14:28,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:44436'
2024-08-09 06:14:28,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:34868'
2024-08-09 06:14:28,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:39359'
2024-08-09 06:14:28,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:36771'
2024-08-09 06:14:28,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:35554'
2024-08-09 06:14:28,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:46393'
2024-08-09 06:14:28,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:38075'
2024-08-09 06:14:28,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.34.59.4:42767'
2024-08-09 06:14:29,689 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:45565
2024-08-09 06:14:29,690 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:45565
2024-08-09 06:14:29,690 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-0
2024-08-09 06:14:29,690 - distributed.worker - INFO -          dashboard at:           10.34.59.4:35671
2024-08-09 06:14:29,690 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,690 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,690 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,690 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,690 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kjimfsvd
2024-08-09 06:14:29,690 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,693 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:39531
2024-08-09 06:14:29,693 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:39531
2024-08-09 06:14:29,693 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-3
2024-08-09 06:14:29,693 - distributed.worker - INFO -          dashboard at:           10.34.59.4:45506
2024-08-09 06:14:29,693 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,693 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:43135
2024-08-09 06:14:29,693 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,693 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:43134
2024-08-09 06:14:29,693 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,693 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:43135
2024-08-09 06:14:29,693 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:43134
2024-08-09 06:14:29,693 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,693 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-2
2024-08-09 06:14:29,693 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uk_70l4e
2024-08-09 06:14:29,693 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-1
2024-08-09 06:14:29,694 - distributed.worker - INFO -          dashboard at:           10.34.59.4:35857
2024-08-09 06:14:29,694 - distributed.worker - INFO -          dashboard at:           10.34.59.4:44255
2024-08-09 06:14:29,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,694 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,694 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,694 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,694 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,694 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,694 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,694 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kcqwdydt
2024-08-09 06:14:29,694 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-emd6zwwg
2024-08-09 06:14:29,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,694 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,695 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:38436
2024-08-09 06:14:29,696 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:38436
2024-08-09 06:14:29,696 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-4
2024-08-09 06:14:29,696 - distributed.worker - INFO -          dashboard at:           10.34.59.4:32875
2024-08-09 06:14:29,696 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,696 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,696 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,696 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,696 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-86qwx17c
2024-08-09 06:14:29,696 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,702 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:35832
2024-08-09 06:14:29,702 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:35832
2024-08-09 06:14:29,702 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-6
2024-08-09 06:14:29,702 - distributed.worker - INFO -          dashboard at:           10.34.59.4:37629
2024-08-09 06:14:29,702 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,702 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,702 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,702 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,702 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jbnb1s4q
2024-08-09 06:14:29,702 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,706 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42011
2024-08-09 06:14:29,706 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42011
2024-08-09 06:14:29,706 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-8
2024-08-09 06:14:29,706 - distributed.worker - INFO -          dashboard at:           10.34.59.4:38495
2024-08-09 06:14:29,706 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,706 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,706 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,706 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,706 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gph2droq
2024-08-09 06:14:29,706 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,707 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:40171
2024-08-09 06:14:29,707 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:40171
2024-08-09 06:14:29,707 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-7
2024-08-09 06:14:29,707 - distributed.worker - INFO -          dashboard at:           10.34.59.4:45291
2024-08-09 06:14:29,707 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,707 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,707 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,707 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,707 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-4g4ynzae
2024-08-09 06:14:29,707 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,707 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:45742
2024-08-09 06:14:29,707 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:45742
2024-08-09 06:14:29,708 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-5
2024-08-09 06:14:29,708 - distributed.worker - INFO -          dashboard at:           10.34.59.4:42116
2024-08-09 06:14:29,708 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,708 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,708 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,708 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,708 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-o9c31erp
2024-08-09 06:14:29,708 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,711 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:38572
2024-08-09 06:14:29,711 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:38572
2024-08-09 06:14:29,711 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-10
2024-08-09 06:14:29,711 - distributed.worker - INFO -          dashboard at:           10.34.59.4:46874
2024-08-09 06:14:29,711 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,711 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,711 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,711 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,711 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6fefknfn
2024-08-09 06:14:29,711 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,718 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:46493
2024-08-09 06:14:29,719 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:46493
2024-08-09 06:14:29,719 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-13
2024-08-09 06:14:29,719 - distributed.worker - INFO -          dashboard at:           10.34.59.4:37801
2024-08-09 06:14:29,719 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,719 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,719 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,719 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,719 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2utg7gbl
2024-08-09 06:14:29,719 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,719 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:38465
2024-08-09 06:14:29,720 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:46213
2024-08-09 06:14:29,720 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:38465
2024-08-09 06:14:29,720 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:46213
2024-08-09 06:14:29,720 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-11
2024-08-09 06:14:29,720 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-12
2024-08-09 06:14:29,720 - distributed.worker - INFO -          dashboard at:           10.34.59.4:40458
2024-08-09 06:14:29,720 - distributed.worker - INFO -          dashboard at:           10.34.59.4:42879
2024-08-09 06:14:29,720 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,720 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,720 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,720 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,720 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,720 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,720 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,720 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,720 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pzlgoqrc
2024-08-09 06:14:29,720 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tbqtgkq4
2024-08-09 06:14:29,720 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,720 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,723 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42404
2024-08-09 06:14:29,723 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42404
2024-08-09 06:14:29,724 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-14
2024-08-09 06:14:29,724 - distributed.worker - INFO -          dashboard at:           10.34.59.4:37868
2024-08-09 06:14:29,724 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,724 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,724 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,724 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,724 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ij5t8oxc
2024-08-09 06:14:29,724 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,729 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:42895
2024-08-09 06:14:29,729 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:42895
2024-08-09 06:14:29,729 - distributed.worker - INFO -           Worker name:          SLURMCluster-1-15
2024-08-09 06:14:29,729 - distributed.worker - INFO -          dashboard at:           10.34.59.4:46100
2024-08-09 06:14:29,729 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,729 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,729 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,729 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,729 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-t7x2_xff
2024-08-09 06:14:29,729 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,739 - distributed.worker - INFO -       Start worker at:     tcp://10.34.59.4:39213
2024-08-09 06:14:29,739 - distributed.worker - INFO -          Listening to:     tcp://10.34.59.4:39213
2024-08-09 06:14:29,739 - distributed.worker - INFO -           Worker name:           SLURMCluster-1-9
2024-08-09 06:14:29,739 - distributed.worker - INFO -          dashboard at:           10.34.59.4:38787
2024-08-09 06:14:29,739 - distributed.worker - INFO - Waiting to connect to:     tcp://10.34.59.1:39662
2024-08-09 06:14:29,739 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:29,740 - distributed.worker - INFO -               Threads:                          1
2024-08-09 06:14:29,740 - distributed.worker - INFO -                Memory:                   1.86 GiB
2024-08-09 06:14:29,740 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_1udxvhb
2024-08-09 06:14:29,740 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,071 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,072 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,072 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,075 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,075 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,075 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,081 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,081 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,081 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,092 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,092 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,093 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,093 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,093 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,094 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,094 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,094 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,096 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,096 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,097 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,097 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,097 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,098 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,101 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,102 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,102 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,102 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,102 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,103 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,103 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,103 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,103 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,103 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,104 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,106 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,107 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,107 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,107 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,111 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,111 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,111 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,115 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,115 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,115 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,118 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,119 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,119 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,127 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,128 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,128 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,128 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:30,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-08-09 06:14:30,131 - distributed.worker - INFO -         Registered to:     tcp://10.34.59.1:39662
2024-08-09 06:14:30,131 - distributed.worker - INFO - -------------------------------------------------
2024-08-09 06:14:30,132 - distributed.core - INFO - Starting established connection to tcp://10.34.59.1:39662
2024-08-09 06:14:33,099 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.30 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 06:14:33,466 - distributed.worker.memory - WARNING - Worker is at 87% memory usage. Pausing worker.  Process memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 06:14:33,472 - distributed.worker.memory - WARNING - Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.63 GiB -- Worker memory limit: 1.86 GiB
2024-08-09 06:14:33,776 - distributed.worker.memory - WARNING - Worker is at 8% memory usage. Resuming worker. Process memory: 168.76 MiB -- Worker memory limit: 1.86 GiB
slurmstepd: error: *** JOB 2330429 ON cl-node004 CANCELLED AT 2024-08-09T06:14:40 ***
2024-08-09 06:14:40,046 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:38436. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:35832. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:46493. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:39531. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:46213. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:40171. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42404. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:43134. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:45565. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:43135. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42895. Reason: scheduler-close
2024-08-09 06:14:40,047 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:45742. Reason: scheduler-close
2024-08-09 06:14:40,049 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:39213. Reason: scheduler-close
2024-08-09 06:14:40,050 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:38572. Reason: scheduler-close
2024-08-09 06:14:40,050 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:38465. Reason: scheduler-close
2024-08-09 06:14:40,050 - distributed.worker - INFO - Stopping worker at tcp://10.34.59.4:42011. Reason: scheduler-close
2024-08-09 06:14:40,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60144 remote=tcp://10.34.59.1:39662>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60144 remote=tcp://10.34.59.1:39662>: Stream is closed
2024-08-09 06:14:40,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60132 remote=tcp://10.34.59.1:39662>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60132 remote=tcp://10.34.59.1:39662>: Stream is closed
2024-08-09 06:14:40,052 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60126 remote=tcp://10.34.59.1:39662>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60126 remote=tcp://10.34.59.1:39662>: Stream is closed
2024-08-09 06:14:40,052 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60136 remote=tcp://10.34.59.1:39662>
Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 297, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 307, in write
    convert_stream_closed_error(self, e)
  File "/users/stud/k/kruret00/.local/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.34.59.4:60136 remote=tcp://10.34.59.1:39662>: Stream is closed
2024-08-09 06:14:40,053 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:46836'. Reason: scheduler-close
2024-08-09 06:14:40,056 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,056 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,057 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:40106'. Reason: scheduler-close
2024-08-09 06:14:40,057 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:46393'. Reason: scheduler-close
2024-08-09 06:14:40,057 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:39883'. Reason: scheduler-close
2024-08-09 06:14:40,058 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:45022'. Reason: scheduler-close
2024-08-09 06:14:40,058 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:46878'. Reason: scheduler-close
2024-08-09 06:14:40,059 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,060 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,060 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,060 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,060 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,060 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,061 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,062 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,062 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
2024-08-09 06:14:40,062 - distributed.nanny - INFO - Worker closed
2024-08-09 06:14:40,062 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:35554'. Reason: scheduler-close
2024-08-09 06:14:40,063 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42275'. Reason: scheduler-close
2024-08-09 06:14:40,063 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:38075'. Reason: scheduler-close
2024-08-09 06:14:40,063 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42790'. Reason: scheduler-close
2024-08-09 06:14:40,064 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42308'. Reason: scheduler-close
2024-08-09 06:14:40,064 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:42767'. Reason: scheduler-close
2024-08-09 06:14:40,065 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:34868'. Reason: scheduler-close
2024-08-09 06:14:40,065 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:39359'. Reason: scheduler-close
2024-08-09 06:14:40,065 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:36771'. Reason: scheduler-close
2024-08-09 06:14:40,066 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.34.59.4:44436'. Reason: scheduler-close
2024-08-09 06:14:40,066 - distributed.core - INFO - Received 'close-stream' from tcp://10.34.59.1:39662; closing.
